{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sksurv.preprocessing import OneHotEncoder as SurvOneHotEncoder\n",
    "from sksurv.util import Surv\n",
    "\n",
    "from sksurv.column import encode_categorical\n",
    "from sksurv.column import standardize\n",
    "from sksurv.util import Surv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "def evaluate_model_uno_c(model, test_X, test_y, train_y, times):\n",
    "    pred = model.predict(test_X)\n",
    "    uno_concordance = concordance_index_ipcw(train_y, test_y, pred, tau=times[-1])\n",
    "    return uno_concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_file = 'data/COX_DATA_FULL_LIVING.pkl'\n",
    "pickle_file = '../data/COX_DATA_FULL_LIVING_EXPERIMENTAL.pkl'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "dataset.drop(['DIAG_KI', 'COD_KI'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_categorical=[\n",
    "                \"PRE_TX_TXFUS\", \n",
    "                \"GENDER\",\n",
    "                \"ON_DIALYSIS\", \n",
    "                \"ETHCAT\", \n",
    "                \"ETHCAT_DON\",\n",
    "                'DIAB',\n",
    "                'HCV_SEROSTATUS',  \n",
    "                'LIV_DON_TY',\n",
    "                \"ABO_MAT\", \n",
    "                'HBV_CORE', \n",
    "                \n",
    "            ]\n",
    "yes_numerical = [   \n",
    "                # \"SERUM_CREAT\", # might be data leakage, as it is after the transplant\n",
    "                \"AGE\", \n",
    "                \"AGE_DON\",\n",
    "                \"DIALYSIS_TIME\",                \n",
    "                \"KI_CREAT_PREOP\", # negative importance\n",
    "                \"NPKID\", # negative importance\n",
    "                \"HGT_CM_CALC\",  # negative importance\n",
    "                \"BMI_DON_CALC\", # negative importance\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [x for x in yes_numerical if x != \"PTIME\" and x != \"PSTATUS\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')) # maybe it's better to use not ignore\n",
    "])\n",
    "\n",
    "# Combine transformations for all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, yes_numerical),\n",
    "        ('cat', categorical_transformer, yes_categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set up the final pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Apply preprocessing to X\n",
    "# X = pipeline.fit_transform(dataset[yes_categorical + yes_numerical])\n",
    "\n",
    "# For calculating feature importance\n",
    "categorical_x = encode_categorical(dataset[yes_categorical])\n",
    "numerical_x = standardize(dataset[yes_numerical])\n",
    "X = pd.concat([numerical_x, categorical_x], axis=1)\n",
    "\n",
    "survival_time = dataset[\"PTIME\"].astype(np.float64)\n",
    "event = dataset[\"PSTATUS\"].astype(float).astype(bool)\n",
    "\n",
    "y = Surv.from_arrays(event, survival_time, \"Status\", \"Days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y[\"Status\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6968632652197185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "\n",
    "est = GradientBoostingSurvivalAnalysis(n_estimators=3, learning_rate=1)\n",
    "est.fit(X_train, y_train)\n",
    "est.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# uncoment if you want to calculate permutation importance (data must not be processed by pipeline)\n",
    "result = permutation_importance(est, X_test, y_test, n_repeats=10, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Importance\n",
      "AGE                  0.130638\n",
      "DIAB=3.0             0.018859\n",
      "DIAB=5.0             0.011912\n",
      "DIAB=2.0             0.007063\n",
      "DIALYSIS_TIME        0.005974\n",
      "ON_DIALYSIS=Y        0.005330\n",
      "HGT_CM_CALC          0.000043\n",
      "LIV_DON_TY=4.0       0.000000\n",
      "HCV_SEROSTATUS=ND    0.000000\n",
      "HCV_SEROSTATUS=P     0.000000\n",
      "LIV_DON_TY=10.0      0.000000\n",
      "LIV_DON_TY=11.0      0.000000\n",
      "LIV_DON_TY=12.0      0.000000\n",
      "LIV_DON_TY=2.0       0.000000\n",
      "LIV_DON_TY=3.0       0.000000\n",
      "NPKID                0.000000\n",
      "DIAB=998.0           0.000000\n",
      "LIV_DON_TY=6.0       0.000000\n",
      "LIV_DON_TY=7.0       0.000000\n",
      "LIV_DON_TY=8.0       0.000000\n",
      "LIV_DON_TY=9.0       0.000000\n",
      "LIV_DON_TY=999.0     0.000000\n",
      "ABO_MAT=2.0          0.000000\n",
      "ABO_MAT=3.0          0.000000\n",
      "HBV_CORE=ND          0.000000\n",
      "LIV_DON_TY=5.0       0.000000\n",
      "DIAB=4.0             0.000000\n",
      "KI_CREAT_PREOP       0.000000\n",
      "AGE_DON              0.000000\n",
      "BMI_DON_CALC         0.000000\n",
      "PRE_TX_TXFUS=Y       0.000000\n",
      "GENDER=M             0.000000\n",
      "ETHCAT=2             0.000000\n",
      "ETHCAT=4             0.000000\n",
      "ETHCAT=5             0.000000\n",
      "ETHCAT=6             0.000000\n",
      "ETHCAT=7             0.000000\n",
      "ETHCAT=9             0.000000\n",
      "ETHCAT_DON=2.0       0.000000\n",
      "ETHCAT_DON=4.0       0.000000\n",
      "ETHCAT_DON=5.0       0.000000\n",
      "ETHCAT_DON=6.0       0.000000\n",
      "ETHCAT_DON=7.0       0.000000\n",
      "ETHCAT_DON=9.0       0.000000\n",
      "HBV_CORE=P           0.000000\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# columns = numeric_features + categorical_features\n",
    "\n",
    "importances_df = pd.DataFrame(result.importances_mean, index=X_train.columns)\n",
    "importances_df.columns = ['Importance']\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print out feature importances\n",
    "print(importances_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney-life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
